{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup # To parse html text\n",
    "import json, codecs, os\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('./FORMS/CORPUS_FORM.xml', encoding='utf-8') as fd:\n",
    "    corpus_xml_string_default_front = fd.read().replace(\"</teiCorpus>\",\"\")\n",
    "    \n",
    "corpus_xml_string_default_back = \"</teiCorpus>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_CSV(filename):\n",
    "    return pd.DataFrame.from_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(url):\n",
    "    html_content = requests.get(url).content\n",
    "    return BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_paragraphs(contents):\n",
    "    pragraphs = []\n",
    "    for pragraph in contents:\n",
    "        tmp = pragraph.find_all('p', recursive=False)\n",
    "        if (len(tmp) <= 0):\n",
    "            pragraphs.append(pragraph)\n",
    "        else:\n",
    "            pragraphs.extend(get_leaf_paragraphs(tmp))\n",
    "    return pragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTO_crawler(link, category):\n",
    "    \n",
    "    id_ = link.split(\"-\")[-1].replace(\".htm\", \"\")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        tree = parse_html(link)\n",
    "        \n",
    "        fck = tree.find(class_=\"fck\")\n",
    "        contents = get_leaf_paragraphs(fck.find_all('p', recursive=False))\n",
    "\n",
    "        div = {}\n",
    "\n",
    "        for i in range(len(contents)):\n",
    "            text = contents[i].text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").rstrip().lstrip()\n",
    "            if(text != \"\"):\n",
    "                paragraph_p = {}\n",
    "                paragraph_p[u'p'] = text\n",
    "                div[u\"div\" + str(i + 1)] = paragraph_p\n",
    "                \n",
    "        if(len(div) <= 0):\n",
    "            return None\n",
    "                \n",
    "        #get titles\n",
    "        \n",
    "        titel = tree.find(class_=\"title-2\").text.replace(\"\\r\",\" \").replace(\"\\n\",\" \").rstrip().lstrip()\n",
    "        \n",
    "        date = tree.find(class_=\"date\").text.split(\" \")[0].replace(\"\\r\",\" \").replace(\"\\n\",\" \").rstrip().lstrip()\n",
    "\n",
    "        author = tree.find(class_=\"author\").text.replace(\"\\r\",\" \").replace(\"\\n\",\" \").rstrip().lstrip().lower()\n",
    "\n",
    "        front = tree.find(class_=\"txt-head\").text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").rstrip().lstrip()\n",
    "\n",
    "        domain = category\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    #open TEI format\n",
    "    with codecs.open('./FORMS/TEI_FORM.xml') as fd:\n",
    "        TEI_string = fd.read()\n",
    "\n",
    "\n",
    "    TEI = xmltodict.parse(TEI_string, dict_constructor = dict)\n",
    "\n",
    "    #replace text with format:\n",
    "    TEI['TEI']['@id'] = id_\n",
    "\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['titleStmt']['title'] = titel\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['publicationStmt']['authority'] = author\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['publicationStmt']['date'] = date\n",
    "\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['profileDesc']['textDesc']['domain'][u'@type'] = domain\n",
    "\n",
    "    TEI['TEI']['text']['front'] = front\n",
    "    TEI['TEI']['text']['body'] = div\n",
    "\n",
    "    #return xml\n",
    "    \n",
    "    return \"\\t\" + xmltodict.unparse(TEI, encoding='utf-8', pretty=True).replace(\"\\n\\t\", \"\\n\\t\\t\").replace(\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n\",  \"\").replace(\"</TEI>\", \"\\t</TEI>\") + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('./FORMS/categories_dict.json', 'r', encoding='utf-8') as fp:\n",
    "    categories_dict = json.load(fp)\n",
    "    \n",
    "\n",
    "try:\n",
    "    valid_df = read_CSV(filename = \"./VALIDS/VALIDS.csv\")\n",
    "except:\n",
    "    valid_df =pd.DataFrame(columns=['url','category','day','month','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(\"./LINKS/\")\n",
    "# files = [os.path.splitext(x)[0] for x in files]\n",
    "\n",
    "# for file_name in files:\n",
    "#     df = read_CSV(\"./LINKS/\" + file_name + \".csv\")\n",
    "    \n",
    "#     #try to open or create CORPUS.xml\n",
    "#     try:    \n",
    "#         with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\") as fd:\n",
    "#             fd.read()\n",
    "#     except:\n",
    "#         with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\", 'a', encoding='utf-8') as fp:\n",
    "#             fp.write(corpus_xml_string_default_front.replace(\"TITLE_HERE\", u\"Tuổi Trẻ Online Corpus \" + file_name))\n",
    "    \n",
    "#     for index, row in df.iterrows():\n",
    "#         print \"\\r%d %s\" %(len(df),file_name),\n",
    "        \n",
    "#         TEI_string = TTO_crawler(row.url, categories_dict[row.category])\n",
    "        \n",
    "#         if(TEI_string == None):\n",
    "#             valid_df = valid_df.append(row)\n",
    "#             valid_df.to_csv('./VALIDS/VALIDS.csv')\n",
    "#         else:\n",
    "#             with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\", 'a', encoding='utf-8') as fp:\n",
    "#                 fp.write(TEI_string)\n",
    "\n",
    "#         df = df.drop(index)\n",
    "#         df.to_csv(\"./LINKS/\" + file_name + \".csv\")\n",
    "\n",
    "#     with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\", 'a', encoding='utf-8') as fp:\n",
    "#         fp.write(corpus_xml_string_default_back)\n",
    "        \n",
    "#     os.remove(\"./LINKS/\" + file_name + \".csv\")\n",
    "\n",
    "# print \"\\rFINISHED.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<TEI lang=\"vi\" id=\"665532\">\n",
      "\t\t<teiHeader>\n",
      "\t\t\t<fileDesc>\n",
      "\t\t\t\t<titleStmt>\n",
      "\t\t\t\t\t<title>IS hành quyết 220 người và chôn tập thể</title>\n",
      "\t\t\t\t</titleStmt>\n",
      "\t\t\t\t<publicationStmt>\n",
      "\t\t\t\t\t<date>31/10/2014</date>\n",
      "\t\t\t\t\t<authority>minh anh</authority>\n",
      "\t\t\t\t</publicationStmt>\n",
      "\t\t\t\t<profileDesc>\n",
      "\t\t\t\t\t<textDesc>\n",
      "\t\t\t\t\t\t<domain type=\"CON CAC\"></domain>\n",
      "\t\t\t\t\t</textDesc>\n",
      "\t\t\t\t</profileDesc>\n",
      "\t\t\t</fileDesc>\n",
      "\t\t</teiHeader>\n",
      "\t\t<text>\n",
      "\t\t\t<front>TTO - Ngày 30-10, thi thể của hơn 220 người bị phiến quân Nhà nước Hồi giáo (IS) hành quyết đã được tìm thấy ở miền tây Iraq.</front>\n",
      "\t\t\t<body>\n",
      "\t\t\t\t<div6>\n",
      "\t\t\t\t\t<p>Trước những diễn biến mới nhất liên quan đến IS ở Anbar, chỉ huy quân đội Mỹ - tướng Martin Dempsey, cho biết sẽ cử cố vấn Mỹ đến tỉnh này, nhưng yêu cầu Baghdad trước tiên phải vũ trang cho các bộ lạc người Sunni ở địa phương.</p>\n",
      "\t\t\t\t</div6>\n",
      "\t\t\t\t<div5>\n",
      "\t\t\t\t\t<p>Ngoài ra cũng có thông tin IS có thể đã giết chết 600 tù nhân tại nhà tù ở Mosul mà chúng chiếm giữ hồi tháng 6. Theo tổ chức theo dõi nhân quyền Human Rights Watch, các tù nhân đã bị bắt quỳ dọc theo một khe núi trước khi bị bắn.</p>\n",
      "\t\t\t\t</div5>\n",
      "\t\t\t\t<div4>\n",
      "\t\t\t\t\t<p>Khoảng 150 thi thể khác cũng được tìm thấy trong một hố chôn gần thành phố Ramadi thuộc tỉnh Anbar. Họ cũng được cho là thành viên bộ lạc Albu Nimr, theo các nguồn tin an ninh.</p>\n",
      "\t\t\t\t</div4>\n",
      "\t\t\t\t<div3>\n",
      "\t\t\t\t\t<p>\"Sáng 30-10, chúng tôi tìm thấy các xác chết. Một số tay súng IS nói với chúng tôi rằng đó là những người thuộc lực lượng Sahwa đã chiến đấu chống IS, và đây là đòn trừng phạt dành cho kẻ chống lại IS\", một nhân chứng nói với Reuters.</p>\n",
      "\t\t\t\t</div3>\n",
      "\t\t\t\t<div2>\n",
      "\t\t\t\t\t<p>Các nạn nhân từ 18-55 tuổi, bị IS bắn ở khoảng cách gần, theo lời kể của các nhân chứng. Hầu hết họ là thành viên của lực lượng cảnh sát hoặc của một lực lượng dân quân chống Nhà nước Hồi giáo được gọi là Sahwa (Awakening).</p>\n",
      "\t\t\t\t</div2>\n",
      "\t\t\t\t<div1>\n",
      "\t\t\t\t\t<p>Reuters dẫn lời các nguồn tin an ninh và các nhân chứng cho biết trong số này, có khoảng 70 thi thể bị vứt ở TP Hit thuộc tỉnh Anbar. Họ được cho là thuộc nhóm khoảng 300 người Hồi giáo Sunni thuộc bộ lạc Albu Nimrbị IS bắt giữ trong tuần này.</p>\n",
      "\t\t\t\t</div1>\n",
      "\t\t\t</body>\n",
      "\t\t</text>\n",
      "\t</TEI>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "link = \"https://tuoitre.vn/phat-hien-thi-the-hon-220-nguoi-bi-is-hanh-quyet-665532.htm\"\n",
    "\n",
    "if(TTO_crawler(link, \"test\") == None):\n",
    "    print u\"Lồn má thằng Tuổi trẻ online\"\n",
    "else:\n",
    "    print TTO_crawler(link, \"CON CAC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
