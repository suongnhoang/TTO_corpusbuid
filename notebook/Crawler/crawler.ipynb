{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup # To parse html text\n",
    "import json, codecs, os\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('./FORMS/CORPUS_FORM.xml', encoding='utf-8') as fd:\n",
    "    corpus_xml_string_default_front = fd.read().replace(\"</teiCorpus>\",\"\")\n",
    "    \n",
    "corpus_xml_string_default_back = \"</teiCorpus>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_CSV(filename):\n",
    "    return pd.DataFrame.from_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(url):\n",
    "    html_content = requests.get(url).content\n",
    "    return BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_paragraphs(contents):\n",
    "    pragraphs = []\n",
    "    for pragraph in contents:\n",
    "        tmp = pragraph.find_all('p', recursive=False)\n",
    "        if (len(tmp) <= 0):\n",
    "            pragraphs.append(pragraph)\n",
    "        else:\n",
    "            pragraphs.extend(get_leaf_paragraphs(tmp))\n",
    "    return pragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTO_crawler(link, category):\n",
    "    \n",
    "    id_ = link.split(\"-\")[-1].replace(\".htm\", \"\")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        tree = parse_html(link)\n",
    "        \n",
    "        fck = tree.find(class_=\"fck\")\n",
    "        contents = get_leaf_paragraphs(fck.find_all('p', recursive=False))\n",
    "\n",
    "        div = {}\n",
    "\n",
    "        for i in range(len(contents)):\n",
    "            text = contents[i].text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").rstrip().lstrip()\n",
    "            if(text != \"\"):\n",
    "                paragraph_p = {}\n",
    "                paragraph_p[u'p'] = text\n",
    "                div[u\"div\" + str(i + 1)] = paragraph_p\n",
    "                \n",
    "        if(len(div) <= 0):\n",
    "            return None\n",
    "                \n",
    "        #get titles\n",
    "        \n",
    "        titel = tree.find(class_=\"title-2\").text.replace(\"\\r\",\" \").replace(\"\\n\",\" \").rstrip().lstrip()\n",
    "        \n",
    "        date = tree.find(class_=\"date\").text.split(\" \")[0].replace(\"\\r\",\" \").replace(\"\\n\",\" \").rstrip().lstrip()\n",
    "\n",
    "        author = tree.find(class_=\"author\").text.replace(\"\\r\",\" \").replace(\"\\n\",\" \").rstrip().lstrip().lower()\n",
    "\n",
    "        front = tree.find(class_=\"txt-head\").text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").rstrip().lstrip()\n",
    "\n",
    "        resp = category\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    #open TEI format\n",
    "    with codecs.open('./FORMS/TEI_FORM.xml') as fd:\n",
    "        TEI_string = fd.read()\n",
    "\n",
    "\n",
    "    TEI = xmltodict.parse(TEI_string, dict_constructor = dict)\n",
    "\n",
    "    #replace text with format:\n",
    "    TEI['TEI']['@id'] = id_\n",
    "\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['titleStmt']['title'] = titel\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['publicationStmt']['authority'] = author\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['publicationStmt']['date'] = date\n",
    "\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['respStmt']['persName'] = author\n",
    "    TEI['TEI']['teiHeader']['fileDesc']['respStmt']['resp'] = resp\n",
    "\n",
    "    TEI['TEI']['text']['front'] = front\n",
    "    TEI['TEI']['text']['body'] = div\n",
    "\n",
    "    #return xml\n",
    "    \n",
    "    return \"\\t\" + xmltodict.unparse(TEI, encoding='utf-8', pretty=True).replace(\"\\n\\t\", \"\\n\\t\\t\").replace(\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n\",  \"\").replace(\"</TEI>\", \"\\t</TEI>\") + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('./FORMS/categories_dict.json', 'r', encoding='utf-8') as fp:\n",
    "    categories_dict = json.load(fp)\n",
    "    \n",
    "\n",
    "try:\n",
    "    valid_df = read_CSV(filename = \"./VALIDS/VALIDS.csv\")\n",
    "except:\n",
    "    valid_df =pd.DataFrame(columns=['url','category','day','month','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"./LINKS/\")\n",
    "files = [os.path.splitext(x)[0] for x in files]\n",
    "\n",
    "for file_name in files:\n",
    "    df = read_CSV(\"./LINKS/\" + file_name + \".csv\")\n",
    "    \n",
    "    #try to open or create CORPUS.xml\n",
    "    try:    \n",
    "        with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\") as fd:\n",
    "            fd.read()\n",
    "    except:\n",
    "        with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\", 'a', encoding='utf-8') as fp:\n",
    "            fp.write(corpus_xml_string_default_front.replace(\"TITLE_HERE\", u\"Tuổi Trẻ Online Corpus \" + file_name))\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print \"\\r%d %s\" %(len(df),file_name),\n",
    "        \n",
    "        TEI_string = TTO_crawler(row.url, categories_dict[row.category])\n",
    "        \n",
    "        if(TEI_string == None):\n",
    "            valid_df = valid_df.append(row)\n",
    "            valid_df.to_csv('./VALIDS/VALIDS.csv')\n",
    "        else:\n",
    "            with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\", 'a', encoding='utf-8') as fp:\n",
    "                fp.write(TEI_string)\n",
    "\n",
    "        df = df.drop(index)\n",
    "        df.to_csv(\"./LINKS/\" + file_name + \".csv\")\n",
    "\n",
    "    with codecs.open(\"./CORPUS/CORPUS.\"+file_name+\".xml\", 'a', encoding='utf-8') as fp:\n",
    "        fp.write(corpus_xml_string_default_back)\n",
    "        \n",
    "    os.remove(\"./LINKS/\" + file_name + \".csv\")\n",
    "\n",
    "print \"\\rFINISHED.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link = \"https://tuoitre.vn/phat-hien-thi-the-hon-220-nguoi-bi-is-hanh-quyet-665532.htm\"\n",
    "\n",
    "# if(TTO_crawler(link, \"test\") == None):\n",
    "#     print u\"Lồn má thằng Tuổi trẻ online\"\n",
    "# else:\n",
    "#     print TTO_crawler(link, \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
